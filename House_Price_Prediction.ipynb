{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-FgiTjwSvglU"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=fetch_california_housing()\n",
        "x,y=data.data,data.target"
      ],
      "metadata": {
        "id": "xqY3wni6v_V9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n",
        "scaler=StandardScaler()\n",
        "x_train=scaler.fit_transform(x_train)\n",
        "x_test=scaler.transform(x_test)"
      ],
      "metadata": {
        "id": "nKGZZISiwLfE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=tf.keras.Sequential([tf.keras.layers.Dense(64,activation='relu',input_shape=(x_train.shape[1],)), tf.keras.layers.Dense(1)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jVVK7g_wl-A",
        "outputId": "9c9bcffe-1821-45d7-c8dc-550b704d212f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='mse',metrics=['mae'])\n",
        "model.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))\n",
        "model.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VS7NBr9_xKqS",
        "outputId": "276cc0b6-c788-4d15-cc1a-eedbf49afc57"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1.9597 - mae: 0.9706 - val_loss: 0.7135 - val_mae: 0.5195\n",
            "Epoch 2/10\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.4876 - mae: 0.4984 - val_loss: 0.3973 - val_mae: 0.4608\n",
            "Epoch 3/10\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4158 - mae: 0.4621 - val_loss: 0.3795 - val_mae: 0.4421\n",
            "Epoch 4/10\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3953 - mae: 0.4500 - val_loss: 0.3744 - val_mae: 0.4378\n",
            "Epoch 5/10\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.4012 - mae: 0.4482 - val_loss: 0.3485 - val_mae: 0.4251\n",
            "Epoch 6/10\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.3910 - mae: 0.4383 - val_loss: 0.3469 - val_mae: 0.4291\n",
            "Epoch 7/10\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3730 - mae: 0.4304 - val_loss: 0.3708 - val_mae: 0.4199\n",
            "Epoch 8/10\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3608 - mae: 0.4248 - val_loss: 0.3717 - val_mae: 0.4120\n",
            "Epoch 9/10\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.4319 - mae: 0.4344 - val_loss: 0.3270 - val_mae: 0.4125\n",
            "Epoch 10/10\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.3562 - mae: 0.4202 - val_loss: 0.3281 - val_mae: 0.4044\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3096 - mae: 0.3969\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.32808488607406616, 0.40443843603134155]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}